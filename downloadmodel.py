import os
import sys
from transformers import TRANSFORMERS_CACHE, AutoTokenizer, AutoModelForSeq2SeqLM

# æ¨¡å‹çš„åç§°
MODEL_NAME = "Salesforce/codet5-base"
MIRROR_ENDPOINT = "https://hf-mirror.com"
ORIGINAL_ENDPOINT = "https://huggingface.co"

# --- æ ¸å¿ƒä¿®æ”¹ï¼šè®¾ç½® Hugging Face é•œåƒ ---
os.environ["HF_ENDPOINT"] = MIRROR_ENDPOINT


# =======================================================
# è¯Šæ–­å‡½æ•°ï¼šä½¿ç”¨ Python å†…ç½®åº“æµ‹è¯•è¿æ¥
# =======================================================

def run_connection_test(url, timeout=5):
    """å°è¯•ä½¿ç”¨ Python æ ‡å‡†åº“æµ‹è¯•è¿æ¥"""
    try:
        import urllib.request
        print(f"   -> Testing: {url}...")
        # å°è¯•å‘èµ· HEAD è¯·æ±‚
        req = urllib.request.Request(url, method='HEAD')
        with urllib.request.urlopen(req, timeout=timeout) as response:
            status = response.getcode()
            if status in [200, 307]:
                return True, f"Success (Status {status})"
            else:
                return False, f"HTTP Error (Status {status})"
    except ImportError:
        # Fallback if urllib.request is not available (unlikely)
        return False, "urllib.request not found."
    except Exception as e:
        return False, f"Connection Failed: {type(e).__name__} - {e}"

# =======================================================
# ä¸»æ‰§è¡Œæµç¨‹
# =======================================================

print(f"Transformers cache directory: {TRANSFORMERS_CACHE}")
print(f"Loading model: {MODEL_NAME} via mirror: {os.environ['HF_ENDPOINT']}...")
print("-" * 40)


try:
    # å®˜æ–¹ä¸‹è½½æ–¹æ³•ï¼Œé€šè¿‡ HF_ENDPOINT æŒ‡å‘çš„é•œåƒä¸‹è½½
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)

    print("\nâœ… æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸï¼")
    print("Tokenizer type:", type(tokenizer))
    print("Model type:", type(model))

except Exception as e:
    # =======================================================
    # å¤±è´¥è¯Šæ–­éƒ¨åˆ†
    # =======================================================
    print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ­£åœ¨è¿›è¡Œè¯¦ç»†è¯Šæ–­...")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    print("\n--- Python ç¯å¢ƒç½‘ç»œè¯Šæ–­ ---")
    
    # 1. æ£€æŸ¥ä»£ç†è®¾ç½®
    print(f"1. Proxy Check (from os.environ):")
    print(f"   - HTTP_PROXY: {os.environ.get('HTTP_PROXY', 'Not set')}")
    print(f"   - HTTPS_PROXY: {os.environ.get('HTTPS_PROXY', 'Not set')}")

    # 2. å°è¯•è¿æ¥é•œåƒæº
    test_mirror_url = f"{MIRROR_ENDPOINT}/Salesforce/codet5-base/resolve/main/config.json"
    is_mirror_ok, mirror_result = run_connection_test(test_mirror_url)
    print(f"\n2. Mirror Connection ({MIRROR_ENDPOINT}):")
    print(f"   - Result: {'SUCCESS' if is_mirror_ok else 'FAILED'}")
    print(f"   - Detail: {mirror_result}")

    # 3. å°è¯•è¿æ¥åŸå§‹æº (ç”¨äºå¯¹æ¯”ï¼Œçœ‹æ˜¯å¦ç½‘ç»œå®Œå…¨ä¸é€š)
    test_original_url = f"{ORIGINAL_ENDPOINT}/Salesforce/codet5-base/resolve/main/config.json"
    is_original_ok, original_result = run_connection_test(test_original_url)
    print(f"\n3. Original Connection ({ORIGINAL_ENDPOINT}):")
    print(f"   - Result: {'SUCCESS' if is_original_ok else 'FAILED'}")
    print(f"   - Detail: {original_result}")

    # 4. æ ¹æ®è¯Šæ–­ç»“æœç»™å‡ºå»ºè®®
    print("\n--- è¯Šæ–­å»ºè®® ---")
    if not is_mirror_ok:
        if "TimeoutError" in mirror_result or "ConnectTimeoutError" in mirror_result:
             print("ğŸ’¡ ç»“è®º: Python ç¯å¢ƒè¿æ¥ **é•œåƒæº** æ—¶å‘ç”Ÿ**è¶…æ—¶**ã€‚")
             print("   - æ£€æŸ¥é˜²ç«å¢™æˆ–ç½‘ç»œè®¿é—®æ§åˆ¶åˆ—è¡¨ (ACL)ã€‚")
             print("   - å¦‚æœä½¿ç”¨äº†ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†è®¾ç½®ï¼ˆHTTP_PROXY/HTTPS_PROXYï¼‰åœ¨è„šæœ¬è¿è¡Œå‰å·²æ­£ç¡®å¯¼å…¥ã€‚")
        elif "SSLError" in mirror_result:
             print("ğŸ’¡ ç»“è®º: Python ç¯å¢ƒè¿æ¥ **é•œåƒæº** æ—¶å‘ç”Ÿ **SSLè¯ä¹¦é”™è¯¯**ã€‚")
             print("   - å°è¯•å‡çº§ `certifi` åº“ï¼Œæˆ–ç¡®è®¤ç³»ç»Ÿè¯ä¹¦å®Œæ•´æ€§ã€‚")
        else:
             print("ğŸ’¡ ç»“è®º: Python ç¯å¢ƒæ— æ³•é€šè¿‡ä»»ä½•æ–¹å¼è¿æ¥åˆ°é•œåƒæºã€‚")
             
    if is_original_ok and not is_mirror_ok:
        print("âš ï¸ å¥‡æ€ª! åŸå§‹ Hugging Face å¯é€šï¼Œä½†é•œåƒä¸é€šã€‚å°è¯•ç§»é™¤ HF_ENDPOINT å˜é‡ã€‚")

    # 5. æç¤ºæœ¬åœ°ä¸‹è½½
    print("\n--- æœ¬åœ°åŠ è½½æç¤º ---")
    print("ğŸ’¡ æ— è®ºå¦‚ä½•ï¼Œæœ€å¯é çš„è§£å†³æ–¹æ¡ˆæ˜¯ **æ‰‹åŠ¨ä¸‹è½½** æ¨¡å‹æ–‡ä»¶åï¼Œä»æœ¬åœ°è·¯å¾„åŠ è½½ã€‚")
    try:
        from transformers.utils import cached_file
        local_config_path = cached_file(MODEL_NAME, "config.json")
        local_model_path = os.path.dirname(local_config_path)
        print(f"ğŸ” å¦‚æœæ–‡ä»¶å·²éƒ¨åˆ†ç¼“å­˜ï¼Œæœ¬åœ°è·¯å¾„å¯èƒ½åœ¨: {local_model_path}")
    except:
        pass

    # é€€å‡ºç¨‹åºï¼Œé¿å…ç»§ç»­æ‰§è¡Œ
    sys.exit(1)

# import os

# # âœ… å¿…é¡»æ”¾åœ¨æœ€å‰é¢ï¼ç¡®ä¿æ‰€æœ‰åç»­åº“éƒ½ä½¿ç”¨é•œåƒ
# os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# from transformers import AutoTokenizer, AutoModel

# # æŸ¥çœ‹ç¼“å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
# from transformers import TRANSFORMERS_CACHE
# print(f"Transformers cache directory: {TRANSFORMERS_CACHE}")

# # âœ… ä½¿ç”¨ AutoTokenizer å’Œ AutoModel åŠ è½½ CodeBERTï¼ˆä¸æ˜¯ RobertaTokenizer/Modelï¼‰
# model_name = "microsoft/codebert-base"

# print(f"Loading model: {model_name} from {os.environ['HF_ENDPOINT']}")

# # è‡ªåŠ¨ä»é•œåƒç«™ä¸‹è½½å¹¶ç¼“å­˜
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModel.from_pretrained(model_name, use_safetensors=True) 

# print("âœ… æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸï¼")
# print("Tokenizer type:", type(tokenizer))
# print("Model type:", type(model))
# å†åŠ ä¸€ä¸ªçœ‹localpathçš„ä»£ç 